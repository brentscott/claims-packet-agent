# LlamaCloud API Configuration
# Required for document parsing, classification, and extraction
LLAMA_CLOUD_API_KEY=

# OpenAI API Configuration
# Required for LLM-based summary generation (Step 5)
# Default model: gpt-4o-mini (can be changed in process_file.py)
OPENAI_API_KEY=

# Optional: Custom LlamaCloud Base URL
# Defaults to official LlamaCloud endpoint if not specified
# LLAMA_CLOUD_BASE_URL=

# Optional: LlamaCloud Deployment Configuration
# Set automatically by llamactl when deploying
# LLAMA_DEPLOY_DEPLOYMENT_NAME=
# LLAMA_DEPLOY_PROJECT_ID=

# Optional: Logging Configuration
# Set log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# LOG_LEVEL=INFO

# Optional: LLM Summary Configuration
# Model to use for patient-friendly summary generation
# SUMMARY_LLM_MODEL=gpt-4o-mini
# Summary generation temperature (0.0-1.0, lower = more deterministic)
# SUMMARY_LLM_TEMPERATURE=0.0
# Maximum tokens for summary (default: 1000)
# SUMMARY_LLM_MAX_TOKENS=1000

# Optional: Frontend Configuration
# Base URL for API calls from React UI
# REACT_APP_API_BASE_URL=http://localhost:8000

# Optional: Document Processing Configuration
# Maximum file size for document upload (in MB)
# MAX_UPLOAD_SIZE_MB=50
# Supported document types (comma-separated)
# SUPPORTED_DOCUMENT_TYPES=pdf
